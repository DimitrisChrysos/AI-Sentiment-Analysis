# ğŸ§  AI Sentiment Analysis

This repository contains three sentiment classification models developed for the course **Artificial Intelligence II â€“ Deep Learning for NLP** (Spring 2024â€“2025). The models classify English-language tweets into positive or negative sentiment using increasingly advanced techniques.

---

## ğŸ“‚ Project Structure

```
AI-Sentiment-Analysis/
â”œâ”€ Assignment1/                # TF-IDF + Logistic Regression
â”‚  â”œâ”€ instructions.pdf    
â”‚  â”œâ”€ report.pdf
â”‚  â””â”€ tfidf-notebook.ipynb
â”œâ”€ Assignment2/                # Neural Network + Word2Vec
â”‚  â”œâ”€ instructions.pdf    
â”‚  â”œâ”€ report.pdf
â”‚  â””â”€ neural-networks-notebook.ipynb
â”œâ”€ Assignment1/                # Fine-tuned Transformers (BERT & DistilBERT)
â”‚  â”œâ”€ instructions.pdf    
â”‚  â”œâ”€ report.pdf
â”‚  â”œâ”€ distilbert-notebook.ipynb
â”‚  â””â”€ bert-notebook.ipynb
â”œâ”€ README.md                   # Project overview and documentation
```
**Reports** within the assignments are documents that include details on data processing steps, such as preprocessing, analysis, and vectorization, followed by experiments, hyperparameter tuning, optimization techniques, and evaluation. Each report concludes with an overall analysis of the results and a summary of the best-performing trials, including a comparison with previous approaches (assignments).

**Instructions** refer to the official assignment guidelines provided for each task.

The **.ipynb files** are notebooks that include the code, experiments, and the process leading to the final selected model for each assignment.

---

## ğŸ“ Assignments Overview

### ğŸ”¹ Assignment 1: TF-IDF + Logistic Regression
A classical machine learning approach using TF-IDF vectorization and logistic regression. Serves as a strong baseline for sentiment classification.

### ğŸ”¹ Assignment 2: Neural Network + Word2Vec
A feedforward neural network built with PyTorch, leveraging Word2Vec embeddings for semantic understanding of tweet content.

### ğŸ”¹ Assignment 3: Fine-tuned Transformers (BERT & DistilBERT)
State-of-the-art transformer-based models fine-tuned using HuggingFaceâ€™s `transformers` library for high-accuracy sentiment classification.

---

## ğŸ§° Technologies Used

- Python â‰¥ 3.8
- `scikit-learn`
- `PyTorch`
- `HuggingFace Transformers`
- `gensim`
- `pandas`, `numpy`, `matplotlib`, `seaborn`
